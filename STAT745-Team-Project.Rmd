---
title: "STAT745-Team-Project"
author: "Lincoln Mercuro"
date: "2025-03-20"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(readr)
library(dplyr)
library(ggplot2)
library(tidyr)
library(randomForest)
library(caretEnsemble)
library(ranger)      # for method = "ranger" in caret
library(caret)       # for easy model tuning and cross-validation
library(xgboost)     # for gradient boosting
library(Matrix)
library(glmnet)
set.seed(123)        # for reproducibility
```

```{R}
titanic <- read.csv("train.csv")
head(titanic)
```

```{R}
str(titanic)

# Count missing values in each column
colSums(is.na(titanic))

# Summary statistics of numeric variables
summary(titanic)
```

```{R}
# Quick table of Survived
table(titanic$Survived)
```

```{R}
########################################
# 3) Visualize Missing Data
########################################

# A fast way to check missingness distribution is to reshape or do a simple bar plot:
titanic_miss <- titanic %>%
  mutate(
    Age_miss = is.na(Age),
    # (Repeat for other columns if you want)
  )

ggplot(titanic_miss, aes(x = Age_miss)) +
  geom_bar() +
  labs(
    x = "Is Age Missing?",
    y = "Count",
    title = "Count of Missing vs. Not-Missing Age"
  )

# Alternatively, packages like naniar or VIM can create specialized missing-data plots.
```

```{R}
########################################
# 5) Bivariate Distributions
########################################

# A) Survival Rate by Sex
ggplot(titanic, aes(x = Sex, fill = factor(Survived))) +
  geom_bar(position = "fill") +  # "fill" shows proportions
  scale_y_continuous(labels = scales::percent_format()) +
  labs(
    title = "Proportion Survived by Sex",
    x = "Sex",
    y = "Proportion",
    fill = "Survived"
  )

# B) Survival Rate by Passenger Class
ggplot(titanic, aes(x = factor(Pclass), fill = factor(Survived))) +
  geom_bar(position = "fill") +
  scale_y_continuous(labels = scales::percent_format()) +
  labs(
    title = "Proportion Survived by Class",
    x = "Passenger Class",
    y = "Proportion",
    fill = "Survived"
  )

# C) Age vs Survived: boxplot
ggplot(titanic, aes(x = factor(Survived), y = Age)) +
  geom_boxplot(na.rm = TRUE) +
  labs(
    title = "Boxplot of Age by Survived",
    x = "Survived",
    y = "Age"
  )

# D) Age vs Fare (if Fare exists) with color = Survived
# This shows a possible relationship among Age, Fare, and Survival
if ("Fare" %in% colnames(titanic)) {
  ggplot(titanic, aes(x = Age, y = Fare, color = factor(Survived))) +
    geom_point(na.rm = TRUE, alpha = 0.6) +
    labs(
      title = "Age vs. Fare (colored by Survival)",
      x = "Age",
      y = "Fare",
      color = "Survived"
    )
}
```

```{R}
########################################
# 6) Grouped Summaries & Additional Checks
########################################

# Group by Class and Sex, then look at average Age, Survived rate
titanic %>%
  group_by(Pclass, Sex) %>%
  summarize(
    Avg_Age       = mean(Age, na.rm = TRUE),
    Survived_Rate = mean(Survived, na.rm = TRUE),
    n             = n()
  ) %>%
  arrange(Pclass, Sex)

# Correlation among numerical columns (Age, SibSp, Parch, Fare, etc.)
# (Will ignore Survived in the correlation for now, as it's 0/1)
num_cols <- c("Age", "SibSp", "Parch")
if ("Fare" %in% colnames(titanic)) {
  num_cols <- c(num_cols, "Fare")
}
num_data <- titanic[, num_cols]
num_data <- num_data[complete.cases(num_data), ]  # optional: remove rows w/ NAs

# Basic correlation matrix
cor(num_data)

```


```{R}
# ---- data-prep ----
# assume titanic_clean already has:
# Survived(No/Yes), Pclass, Sex, Age, SibSp, Parch, Embarked,
# Title, FamilySize, LogFare, AgeGroup
titanic_clean <- clean_titanic(titanic)

# Add Embarked if missing:
titanic_clean$Embarked <- factor(titanic_clean$Embarked)

# Choose features
features <- c("Pclass","Sex","Age","SibSp","Parch",
              "Embarked","Title","FamilySize","LogFare","AgeGroup")

# Create model matrix (one-hot encode factors)
dummies <- dummyVars(~ ., data = titanic_clean[,features])
X <- predict(dummies, newdata = titanic_clean[,features])
X <- as(Matrix(X), "dgCMatrix")

# Label: 0/1 numeric
y <- ifelse(titanic_clean$Survived == "Yes", 1, 0)

# Create DMatrix
dtrain <- xgb.DMatrix(data = X, label = y)
# ---- xgb-train ----
params <- list(
  objective = "binary:logistic",
  eval_metric = "error",    # classification error
  eta = 0.1,
  max_depth = 6,
  subsample = 0.8,
  colsample_bytree = 0.8,
  gamma = 0
)

set.seed(123)
xgb_model <- xgb.train(
  params = params,
  data = dtrain,
  nrounds = 200,
  watchlist = list(train = dtrain),
  verbose = 0
)

```


```{R}
# ---- importance ----
# Get importance matrix
imp <- xgb.importance(
  feature_names = colnames(X),
  model = xgb_model
)

# View top 10
print(imp)

# Plot importance
xgb.plot.importance(imp)

```



```{R}
train_data <- clean_titanic(titanic)

train_control <- trainControl(
  method = "repeatedcv", 
  number = 5,     # 5-fold
  repeats = 3,    # repeated 3x
  classProbs = TRUE,
  summaryFunction = twoClassSummary
)

model_methods <- c("glm", 
                   "rf", 
                   "xgbTree", 
                   "rpart", 
                   "gbm", 
                   "svmRadial", 
                   "knn", 
                   "nnet")  # optional if you want neural nets

formula <- Survived ~ Pclass + Sex + LogFare + Embarked + Title + FamilySize + AgeGroup

# A helper function to train one model:
train_one_model <- function(method_name, formula, data, train_control) {
  set.seed(123)  # or a different seed if you want each model to have a distinct seed
  train(
    formula,
    data      = data,
    method    = method_name,
    trControl = train_control,
    metric    = "Accuracy",      # or "Accuracy", "Kappa", etc.
    tuneLength = 5,         # basic tuning search
    # Optional: If you prefer a custom tuneGrid:
    # tuneGrid = data.frame( ... )  
    preProcess = c("center","scale")  # many models like scaled data
  )
}

# Apply to each method
all_models <- lapply(model_methods, train_one_model, 
                     formula        = formula, 
                     data           = train_data, 
                     train_control  = train_control)

# Give names to the list elements so we know which is which
names(all_models) <- model_methods
```


```{R}
results <- resamples(all_models)

# Print a summary of cross-validated statistics for each model
summary(results)

# Visual comparison (dotplot of ROC by default)
dotplot(results, metric = "ROC")
```

```{R}
best_model <- all_models[["rf"]]

# Predict on validation
valid_preds <- predict(best_model, newdata = valid_data, type = "raw")
confusionMatrix(valid_preds, valid_data$Survived, positive = "Yes")
```