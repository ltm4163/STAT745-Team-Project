---
title: "STAT745-Team-Project"
author: "Lincoln Mercuro"
date: "2025-03-20"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(readr)
library(dplyr)
library(ggplot2)
library(tidyr)
library(randomForest)
library(caretEnsemble)
library(ranger)      # for method = "ranger" in caret
library(caret)       # for easy model tuning and cross-validation
library(xgboost)     # for gradient boosting
library(Matrix)
set.seed(123)        # for reproducibility
```

```{R}
titanic <- read.csv("train.csv")
head(titanic)
```

```{R}
str(titanic)

# Count missing values in each column
colSums(is.na(titanic))

# Summary statistics of numeric variables
summary(titanic)
```

```{R}
# Quick table of Survived
table(titanic$Survived)
```

```{R}
########################################
# 3) Visualize Missing Data
########################################

# A fast way to check missingness distribution is to reshape or do a simple bar plot:
titanic_miss <- titanic %>%
  mutate(
    Age_miss = is.na(Age),
    # (Repeat for other columns if you want)
  )

ggplot(titanic_miss, aes(x = Age_miss)) +
  geom_bar() +
  labs(
    x = "Is Age Missing?",
    y = "Count",
    title = "Count of Missing vs. Not-Missing Age"
  )

# Alternatively, packages like naniar or VIM can create specialized missing-data plots.
```

```{R}
########################################
# 5) Bivariate Distributions
########################################

# A) Survival Rate by Sex
ggplot(titanic, aes(x = Sex, fill = factor(Survived))) +
  geom_bar(position = "fill") +  # "fill" shows proportions
  scale_y_continuous(labels = scales::percent_format()) +
  labs(
    title = "Proportion Survived by Sex",
    x = "Sex",
    y = "Proportion",
    fill = "Survived"
  )

# B) Survival Rate by Passenger Class
ggplot(titanic, aes(x = factor(Pclass), fill = factor(Survived))) +
  geom_bar(position = "fill") +
  scale_y_continuous(labels = scales::percent_format()) +
  labs(
    title = "Proportion Survived by Class",
    x = "Passenger Class",
    y = "Proportion",
    fill = "Survived"
  )

# C) Age vs Survived: boxplot
ggplot(titanic, aes(x = factor(Survived), y = Age)) +
  geom_boxplot(na.rm = TRUE) +
  labs(
    title = "Boxplot of Age by Survived",
    x = "Survived",
    y = "Age"
  )

# D) Age vs Fare (if Fare exists) with color = Survived
# This shows a possible relationship among Age, Fare, and Survival
if ("Fare" %in% colnames(titanic)) {
  ggplot(titanic, aes(x = Age, y = Fare, color = factor(Survived))) +
    geom_point(na.rm = TRUE, alpha = 0.6) +
    labs(
      title = "Age vs. Fare (colored by Survival)",
      x = "Age",
      y = "Fare",
      color = "Survived"
    )
}
```

```{R}
########################################
# 6) Grouped Summaries & Additional Checks
########################################

# Group by Class and Sex, then look at average Age, Survived rate
titanic %>%
  group_by(Pclass, Sex) %>%
  summarize(
    Avg_Age       = mean(Age, na.rm = TRUE),
    Survived_Rate = mean(Survived, na.rm = TRUE),
    n             = n()
  ) %>%
  arrange(Pclass, Sex)

# Correlation among numerical columns (Age, SibSp, Parch, Fare, etc.)
# (Will ignore Survived in the correlation for now, as it's 0/1)
num_cols <- c("Age", "SibSp", "Parch")
if ("Fare" %in% colnames(titanic)) {
  num_cols <- c(num_cols, "Fare")
}
num_data <- titanic[, num_cols]
num_data <- num_data[complete.cases(num_data), ]  # optional: remove rows w/ NAs

# Basic correlation matrix
cor(num_data)

```

```{R}
clean_titanic <- function(df, is_train = TRUE) {
  df <- df %>%
    # 1) Survived → factor("No","Yes") if training data
    { if (is_train) mutate(., 
        Survived = factor(Survived, levels = c(0,1), labels = c("No","Yes"))
      ) else . } %>%
    
    # 2) Pclass → ordered factor
    mutate(Pclass = factor(Pclass, levels = c(1,2,3), ordered = TRUE)) %>%
    
    # 3) Sex → factor
    mutate(Sex = factor(Sex, levels = c("male","female"))) %>%
    
    # 4) Age → impute missing with median
    { 
      med_age <- median(.$Age, na.rm = TRUE)
      mutate(., Age = ifelse(is.na(Age), med_age, Age))
    } %>%
    
    # 5) Fare → impute missing with median, then log-transform
    { 
      med_fare <- median(.$Fare, na.rm = TRUE)
      tmp <- mutate(., Fare = ifelse(is.na(Fare), med_fare, Fare))
      mutate(tmp, LogFare = log1p(Fare))
    } %>%
    
    # 6) Embarked → impute missing/"" with mode, then factor
    { 
      if ("Embarked" %in% names(.)) {
        tmp <- .
        tmp$Embarked[tmp$Embarked == ""] <- NA
        mode_port <- names(which.max(table(tmp$Embarked)))
        tmp$Embarked[is.na(tmp$Embarked)] <- mode_port
        tmp$Embarked <- factor(tmp$Embarked)
        tmp
      } else .
    } %>%
    
    # 7) Title → extract from Name, group rares, factor
    mutate(
      Title = sub("^.*, (.*?)\\..*$", "\\1", Name),
      Title = case_when(
        Title %in% c("Mlle","Ms", "Miss", "Mrs")                        ~ "Other",
        Title %in% c("Mme","Countess","Lady","Dona")     ~ "Other",
        Title %in% c("Capt","Col","Major","Dr","Rev",
                     "Don","Sir","Jonkheer","the Countess") ~ "Other",
        TRUE                                             ~ Title
      ),
      Title = factor(Title)
    ) %>%
    
    # 8) FamilySize
    mutate(FamilySize = SibSp + Parch + 1) %>%
    
    # 9) AgeGroup → bin Age into categories, ordered factor
    mutate(
      AgeGroup = cut(
        Age,
        breaks = c(0,12,19,40,60,Inf),
        labels = c("Child","Teen","Adult","Middle_Aged","Senior"),
        right = FALSE
      ),
      AgeGroup = factor(
        AgeGroup,
        levels = c("Child","Teen","Adult","Middle_Aged","Senior"),
        ordered = TRUE
      )
    )
  
  return(df)
}

```


```{R}
titanic_clean <- clean_titanic(titanic)
head(titanic_clean)
```

```{R}
# ---- data-prep ----
# assume titanic_clean already has:
# Survived(No/Yes), Pclass, Sex, Age, SibSp, Parch, Embarked,
# Title, FamilySize, LogFare, AgeGroup

# Add Embarked if missing:
titanic_clean$Embarked <- factor(titanic_clean$Embarked)

# Choose features
features <- c("Pclass","Sex","Age","SibSp","Parch",
              "Embarked","Title","FamilySize","LogFare","AgeGroup")

# Create model matrix (one-hot encode factors)
dummies <- dummyVars(~ ., data = titanic_clean[,features])
X <- predict(dummies, newdata = titanic_clean[,features])
X <- as(Matrix(X), "dgCMatrix")

# Label: 0/1 numeric
y <- ifelse(titanic_clean$Survived == "Yes", 1, 0)

# Create DMatrix
dtrain <- xgb.DMatrix(data = X, label = y)
# ---- xgb-train ----
params <- list(
  objective = "binary:logistic",
  eval_metric = "error",    # classification error
  eta = 0.1,
  max_depth = 6,
  subsample = 0.8,
  colsample_bytree = 0.8,
  gamma = 0
)

set.seed(123)
xgb_model <- xgb.train(
  params = params,
  data = dtrain,
  nrounds = 200,
  watchlist = list(train = dtrain),
  verbose = 0
)

```


```{R}
# ---- importance ----
# Get importance matrix
imp <- xgb.importance(
  feature_names = colnames(X),
  model = xgb_model
)

# View top 10
print(imp)

# Plot importance
xgb.plot.importance(imp)

```


```{R}
# ---- gradient-boosted-trees ----
# Using xgboost with caret

# For xgboost, we need numeric or dummy variables for factors (caret handles this if we let it).
# Survived must be numeric for xgboost typically, but caret automatically encodes factors.
# Just ensure the formula interface is used or convert Survived to a factor with levels 0/1.

train_control_xgb <- trainControl(
  method = "cv",
  number = 5,
  search="random",
  verboseIter = FALSE
)

# Some typical xgboost tuning parameters for caret's "xgbTree" method:
# nrounds, max_depth, eta, gamma, colsample_bytree, min_child_weight, subsample, etc.

tune_grid_xgb <- expand.grid(
  nrounds          = c(100, 200, 300),
  max_depth        = c(5, 7, 9, 11),
  eta              = c(0.01, 0.1, 0.3),
  gamma            = c(0, 1),
  colsample_bytree = c(0.5, 0.8, 1.0),
  min_child_weight = c(1, 3, 5),
  subsample        = c(0.5, 0.8, 1.0)
)

set.seed(123)
suppressWarnings({
  xgb_expanded <- train(
    Survived ~ Pclass + Sex + Age + FamilySize + LogFare + Title,
    data      = titanic_clean,
    method    = "xgbTree",
    trControl = train_control_xgb,
    tuneGrid  = tune_grid_xgb,
    metric    = "Accuracy",
    tuneLength = 25
  )
})
```

```{R}
xgb_expanded
# Check best results
best_xgb <- xgb_expanded$bestTune
best_xgb
pred_train_xgb <- predict(xgb_expanded, titanic_clean)
conf_mat_xgb   <- table(predicted = pred_train_xgb, actual = titanic_clean$Survived)
accuracy_xgb   <- sum(diag(conf_mat_xgb)) / sum(conf_mat_xgb)
accuracy_xgb
```


```{R}
importance_caret <- varImp(xgb_expanded, scale = FALSE)

# Print the top variables
print(importance_caret)

# Plot the importance
plot(importance_caret)  # show top 10
```

```{R}
# Read the test data
test_data <- read.csv("test.csv", stringsAsFactors = FALSE)

test_clean <- clean_titanic(test_data, is_train=FALSE)

predictions <- predict(xgb_expanded, newdata = test_clean)

# If predictions are factors with levels "0" and "1", Kaggle can generally handle that.
# But to be safe, we can explicitly convert them to numeric 0/1:
predictions_numeric <- ifelse(predictions == "Yes", 1, 0)

# ---- submission-file ----
# Create the submission data frame.
submission <- data.frame(
  PassengerId = test_clean$PassengerId,
  Survived    = predictions_numeric
)

# Preview the first few rows:
head(submission)

# Write out to CSV (no row names)
write.csv(submission, file = "submission.csv", row.names = FALSE)
```
